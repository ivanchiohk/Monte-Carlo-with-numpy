{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a125e3",
   "metadata": {},
   "source": [
    "### Two Montel Carlo examples with numpy\n",
    "\n",
    "The Monte Carlo method is a technique for numerical approximating quantities that are hard to compute or having no closed-form answer. The basic idea comes from the law of large numbers. \n",
    "\n",
    "Here we use numpy to demonstrate the Monte Carlo method by two examples, one using the uniform distribution, and the other one using the exponential distribution.\n",
    "\n",
    "For the first one, we will use Monte Carlo to estimate the value of $\\pi$. The idea is that $\\sqrt{1-x^2}$ is a quarter of the circle centered at $0$ with radius $1$, so the integral $\\int_0^1 4\\sqrt{1-x^2} dx$ would be equal to $\\pi$. \n",
    "\n",
    "In probability term this means that if we denote by $U \\sim \\textrm{Unif}[0,1]$ the uniform distribution on the interval $[0,1]$, then \n",
    "\n",
    "$$ \\mathbb{E}\\left[4\\sqrt{1-U^2} \\right] = \\pi.$$\n",
    "\n",
    "If we use a random generator with distribution $\\mathrm{Unif}[0,1]$ to generate $n$ i.i.d. points $ U_1, U_2, \\cdots, U_n,$ and let $X_i = 4\\sqrt{1-U_i^2}$, then the average\n",
    "\n",
    "$$ \\bar{X_n} = \\frac{1}{n} \\sum_{i=1}^n X_i $$ \n",
    "\n",
    "will converge to this integral which happens to be$\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd30ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edac6c32",
   "metadata": {},
   "source": [
    "First we fix a random seed so we can consistently reproduce the same result. \n",
    "\n",
    "The function __gen_unif_pts__ takes an integer input $k > 0$ and outputs a numpy array of $10^k$ points sampled uniformly from $[0,1]$. So the number of points grows exponentially in $k$.\n",
    "\n",
    "The function __func1__ apply the above math function to the above sampled points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a38f3e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def gen_unif_pts(k):\n",
    "    return np.random.uniform(0,1,10**k)\n",
    "\n",
    "def func1(ui):\n",
    "    return 4*(1-ui**2)**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a977087",
   "metadata": {},
   "source": [
    "Repeat the above procedure for $k=1,...,8$ times. Each time the $\\pi$ estimate using $10^k$ points is stored in the list __pi_estimates__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1f6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_estimates = []\n",
    "\n",
    "for k in range(1,9):\n",
    "    u = gen_unif_pts(k)\n",
    "    x = func1(u)\n",
    "    pi_estimates.append(np.sum(x) / 10**k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe4fdd9",
   "metadata": {},
   "source": [
    "Here are the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f84c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.9531617097666247,\n",
       " 3.2151047907367825,\n",
       " 3.1352154197921207,\n",
       " 3.1548439503506986,\n",
       " 3.1392348757160287,\n",
       " 3.1402910297823166,\n",
       " 3.1418706423044367,\n",
       " 3.141665847411977]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd16806",
   "metadata": {},
   "source": [
    "With the __math__ function we can import the value of $\\pi$. We can look at the convergence by calculating the absolute distance between each estimate and the actual value of $\\pi$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3176e89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18843094382316838,\n",
       " 0.07351213714698934,\n",
       " 0.00637723379767241,\n",
       " 0.013251296760905529,\n",
       " 0.002357777873764455,\n",
       " 0.0013016238074765596,\n",
       " 0.00027798871464357333,\n",
       " 7.319382218407e-05]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = math.pi\n",
    "pi_error = []\n",
    "for val in pi_estimates:\n",
    "    pi_error.append(abs(val-pi))\n",
    "    \n",
    "pi_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de6767",
   "metadata": {},
   "source": [
    "Recall that the number of sampled points grows exponentially in $k$, but even then, the error is converging to $0$ by about a factor of $10$ each iterate, which is rather slow. There are more efficient approximations than Monte Carlo in low dimension integration, but they usually do not generalize to higher dimension, while Monte Carlo does.\n",
    "\n",
    "Meanwhile, we can use distributions other than $\\mathrm{Unif}$ to generate the input values. For example, if we were to approximate the integral\n",
    "$$ \\int_0^\\infty e^{\\sin(\\ln x)) - x^2} dx. $$\n",
    "\n",
    "Recall that the expoential distribution $\\mathrm{Exp}(\\lambda)$ has probability distribution function\n",
    "$$f(x) = \\lambda e^{-\\lambda x}\\quad (x \\geq 0),$$\n",
    "so by rewriting the integral as\n",
    "$$ \\int_0^\\infty e^{\\sin(\\ln x)) - x^2 + x} \\quad e^{-x} dx, $$\n",
    "it can be intepreted as the expectation\n",
    "$$ \\mathbb{E}\\left[ e^{\\sin(\\ln X)) - X^2 + X}\\right] $$\n",
    "with the $\\mathrm{Exp}(1)$ distribution.\n",
    "\n",
    "We can use numpy to generate points with exponential distribution. This time, we use $k=1,...,6$. Then we repeat the above procedure with the new function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1e27e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def gen_exp_pts(k):\n",
    "    return np.random.exponential(1,10**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27c70a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(ui):\n",
    "    return  math.exp(math.sin(math.log(ui))-ui**2 +ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f804f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_estimates = []\n",
    "\n",
    "for k in range(1,7):\n",
    "    \n",
    "    u = gen_exp_pts(k)\n",
    "    x = []\n",
    "    \n",
    "    for ui in u:\n",
    "        x.append(func2(ui))\n",
    "\n",
    "    \n",
    "    integral_estimates.append(np.sum(np.array(x)) / 10**k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c8d43b",
   "metadata": {},
   "source": [
    "Here are the estimates using $n = 10^k$ points for $k=1,...,6$. The actual value of the integral is about 0.65405, but again even with exponentially growing sample points, the convergence by Monte Carlo is still a bit slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db99e5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7051509089068945,\n",
       " 0.6828131850369473,\n",
       " 0.6407661761210932,\n",
       " 0.6574424007887892,\n",
       " 0.6528068662672154,\n",
       " 0.6535148002017594]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integral_estimates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
